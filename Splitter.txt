import re
import unicodedata

def thai_asr_cer(reference, hypothesis, strict_spacing=False):
    """
    CER calculator optimized for Thai ASR evaluation.
    
    Args:
        reference (str): Ground truth Thai text
        hypothesis (str): ASR system output
        strict_spacing (bool): If True, preserves spacing differences
    
    Returns:
        dict: CER results with detailed breakdown
    """
    
    def normalize_thai_text(text, preserve_spacing=False):
        """Normalize Thai text for ASR evaluation."""
        
        # Unicode normalization (NFC - Canonical Decomposition followed by Canonical Composition)
        text = unicodedata.normalize('NFC', text)
        
        # Convert to lowercase (mainly for English mixed in Thai text)
        text = text.lower()
        
        if not preserve_spacing:
            # For Thai ASR, whitespace is often inconsistent
            # Remove all spaces first, then add single spaces around non-Thai characters
            text = re.sub(r'\s+', '', text)  # Remove all whitespace
            
            # Add spaces around English/numbers if mixed with Thai
            text = re.sub(r'([ก-๙])([a-zA-Z0-9])', r'\1 \2', text)  # Thai -> English
            text = re.sub(r'([a-zA-Z0-9])([ก-๙])', r'\1 \2', text)  # English -> Thai
            
        else:
            # Just normalize multiple spaces to single space
            text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def levenshtein_with_details(s1, s2):
        """Calculate edit distance with operation breakdown."""
        m, n = len(s1), len(s2)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        
        # Initialize
        for i in range(m + 1):
            dp[i][0] = i
        for j in range(n + 1):
            dp[0][j] = j
        
        # Fill DP matrix
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if s1[i-1] == s2[j-1]:
                    dp[i][j] = dp[i-1][j-1]
                else:
                    dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
        
        # Backtrack to count operations
        i, j = m, n
        substitutions = deletions = insertions = 0
        
        while i > 0 or j > 0:
            if i > 0 and j > 0 and s1[i-1] == s2[j-1]:
                i -= 1
                j -= 1
            elif i > 0 and j > 0 and dp[i][j] == dp[i-1][j-1] + 1:
                substitutions += 1
                i -= 1
                j -= 1
            elif i > 0 and dp[i][j] == dp[i-1][j] + 1:
                deletions += 1
                i -= 1
            else:
                insertions += 1
                j -= 1
        
        return dp[m][n], substitutions, deletions, insertions
    
    # Normalize texts
    norm_ref = normalize_thai_text(reference, preserve_spacing=strict_spacing)
    norm_hyp = normalize_thai_text(hypothesis, preserve_spacing=strict_spacing)
    
    # Handle edge case
    if len(norm_ref) == 0:
        return {
            'cer': 0.0 if len(norm_hyp) == 0 else 1.0,
            'edit_distance': len(norm_hyp),
            'reference_length': 0,
            'hypothesis_length': len(norm_hyp),
            'substitutions': 0,
            'deletions': 0,
            'insertions': len(norm_hyp),
            'original_reference': reference,
            'original_hypothesis': hypothesis,
            'normalized_reference': norm_ref,
            'normalized_hypothesis': norm_hyp
        }
    
    # Calculate detailed edit distance
    edit_dist, subs, dels, ins = levenshtein_with_details(norm_ref, norm_hyp)
    cer = edit_dist / len(norm_ref)
    
    return {
        'cer': cer,
        'edit_distance': edit_dist,
        'reference_length': len(norm_ref),
        'hypothesis_length': len(norm_hyp),
        'substitutions': subs,
        'deletions': dels,
        'insertions': ins,
        'original_reference': reference,
        'original_hypothesis': hypothesis,
        'normalized_reference': norm_ref,
        'normalized_hypothesis': norm_hyp
    }


def batch_thai_asr_evaluation(references, hypotheses, strict_spacing=False):
    """
    Evaluate multiple Thai ASR outputs.
    
    Args:
        references (list): List of ground truth Thai texts
        hypotheses (list): List of ASR outputs
        strict_spacing (bool): Whether to preserve spacing differences
    
    Returns:
        dict: Comprehensive evaluation results
    """
    if len(references) != len(hypotheses):
        raise ValueError("References and hypotheses must have the same length")
    
    individual_results = []
    total_edit_distance = 0
    total_reference_length = 0
    
    for i, (ref, hyp) in enumerate(zip(references, hypotheses)):
        result = thai_asr_cer(ref, hyp, strict_spacing)
        result['sample_id'] = i
        individual_results.append(result)
        
        total_edit_distance += result['edit_distance']
        total_reference_length += result['reference_length']
    
    # Calculate aggregate metrics
    individual_cers = [r['cer'] for r in individual_results]
    micro_cer = total_edit_distance / total_reference_length if total_reference_length > 0 else 0.0
    macro_cer = sum(individual_cers) / len(individual_cers) if individual_cers else 0.0
    
    # Error type breakdown
    total_subs = sum(r['substitutions'] for r in individual_results)
    total_dels = sum(r['deletions'] for r in individual_results)
    total_ins = sum(r['insertions'] for r in individual_results)
    
    return {
        'individual_results': individual_results,
        'summary': {
            'micro_averaged_cer': micro_cer,
            'macro_averaged_cer': macro_cer,
            'total_samples': len(references),
            'total_edit_distance': total_edit_distance,
            'total_reference_length': total_reference_length,
            'error_breakdown': {
                'substitutions': total_subs,
                'deletions': total_dels,
                'insertions': total_ins
            }
        }
    }


# Example usage with Thai text
if __name__ == "__main__":
    print("=== Thai ASR CER Evaluation Examples ===\n")
    
    # Example 1: Basic Thai text
    ref1 = "สวัสดีครับผมชื่อจอห์น"
    hyp1 = "สวัสดี ครับ ผม ชื่อ จอห์น"
    
    result1 = thai_asr_cer(ref1, hyp1)
    print("Example 1 - Spacing differences:")
    print(f"Reference: '{result1['original_reference']}'")
    print(f"Hypothesis: '{result1['original_hypothesis']}'")
    print(f"Normalized Reference: '{result1['normalized_reference']}'")
    print(f"Normalized Hypothesis: '{result1['normalized_hypothesis']}'")
    print(f"CER: {result1['cer']:.4f}")
    print(f"Edit Distance: {result1['edit_distance']}")
    print()
    
    # Example 2: Character substitution
    ref2 = "ไปกินข้าวกัน"
    hyp2 = "ไปกินขาวกัน"  # ข้าว -> ขาว (tone mark missing)
    
    result2 = thai_asr_cer(ref2, hyp2)
    print("Example 2 - Character substitution:")
    print(f"Reference: '{result2['original_reference']}'")
    print(f"Hypothesis: '{result2['original_hypothesis']}'")
    print(f"CER: {result2['cer']:.4f}")
    print(f"Substitutions: {result2['substitutions']}")
    print(f"Deletions: {result2['deletions']}")
    print(f"Insertions: {result2['insertions']}")
    print()
    
    # Example 3: Mixed Thai-English
    ref3 = "ผมทำงานที่ Google ครับ"
    hyp3 = "ผมทำงานที่google ครับ"
    
    result3 = thai_asr_cer(ref3, hyp3)
    print("Example 3 - Mixed Thai-English:")
    print(f"Reference: '{result3['original_reference']}'")
    print(f"Hypothesis: '{result3['original_hypothesis']}'")
    print(f"Normalized Reference: '{result3['normalized_reference']}'")
    print(f"Normalized Hypothesis: '{result3['normalized_hypothesis']}'")
    print(f"CER: {result3['cer']:.4f}")
    print()
    
    # Example 4: Batch evaluation
    references = [
        "สวัสดีครับ",
        "ไปกินข้าวกัน", 
        "วันนี้อากาศดีมาก"
    ]
    
    hypotheses = [
        "สวัสดี ครับ",
        "ไปกินขาวกัน",
        "วันนี้ อากาศ ดี มาก"
    ]
    
    batch_results = batch_thai_asr_evaluation(references, hypotheses)
    print("Batch Evaluation Results:")
    print(f"Micro-averaged CER: {batch_results['summary']['micro_averaged_cer']:.4f}")
    print(f"Macro-averaged CER: {batch_results['summary']['macro_averaged_cer']:.4f}")
    print(f"Total Error Breakdown:")
    print(f"  Substitutions: {batch_results['summary']['error_breakdown']['substitutions']}")
    print(f"  Deletions: {batch_results['summary']['error_breakdown']['deletions']}")
    print(f"  Insertions: {batch_results['summary']['error_breakdown']['insertions']}")
