docker run --runtime nvidia --gpus all \
  -v ~/base_models/Qwen/Qwen2.5-0.5B-Instruct:/model \
  -p 8080:8000 \
  --ipc=host \
  vllm/vllm-openai:latest \
  --model /model \
  --trust-remote-code \
  --max-model-len 2048 \
  --gpu-memory-utilization 0.9 \
  --served-model-name "qwen-2-5-0-5b-instruct"
