# ==============================================================
# PyTorch Geometric DDP Edge Classification Training Script
# With tqdm progress bars
# ==============================================================
# Run with: torchrun --standalone --nproc_per_node=4 train_edge_ddp.py
# ==============================================================

import os
import torch
import torch.nn as nn
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from torch_geometric.loader import LinkNeighborLoader
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data


# ==============================================================
# 1Ô∏è‚É£ Stratified Edge Split
# ==============================================================

def stratified_edge_split(data, test_size=0.1, val_size=0.1, seed=42):
    edge_index = data.edge_index
    edge_label = data.edge_label

    num_edges = edge_index.size(1)
    idx = torch.arange(num_edges)

    train_idx, test_idx = train_test_split(
        idx.cpu().numpy(),
        test_size=test_size,
        stratify=edge_label.cpu().numpy(),
        random_state=seed,
    )

    train_idx, val_idx = train_test_split(
        train_idx,
        test_size=val_size / (1 - test_size),
        stratify=edge_label[train_idx],
        random_state=seed,
    )

    train_idx = torch.tensor(train_idx)
    val_idx = torch.tensor(val_idx)
    test_idx = torch.tensor(test_idx)

    def subset_edges(indices):
        return edge_index[:, indices], edge_label[indices]

    train_edges, train_labels = subset_edges(train_idx)
    val_edges, val_labels = subset_edges(val_idx)
    test_edges, test_labels = subset_edges(test_idx)

    return (train_edges, train_labels), (val_edges, val_labels), (test_edges, test_labels)


# ==============================================================
# 2Ô∏è‚É£ Neighbor Loaders
# ==============================================================

def get_dataloaders(data, train_edges, val_edges, test_edges,
                    train_labels, val_labels, test_labels,
                    batch_size=4096):

    num_neighbors = [15, 10, 5]

    train_loader = LinkNeighborLoader(
        data,
        edge_label_index=train_edges,
        edge_label=train_labels,
        num_neighbors=num_neighbors,
        batch_size=batch_size,
        shuffle=True,
    )

    val_loader = LinkNeighborLoader(
        data,
        edge_label_index=val_edges,
        edge_label=val_labels,
        num_neighbors=num_neighbors,
        batch_size=batch_size,
        shuffle=False,
    )

    test_loader = LinkNeighborLoader(
        data,
        edge_label_index=test_edges,
        edge_label=test_labels,
        num_neighbors=num_neighbors,
        batch_size=batch_size,
        shuffle=False,
    )

    return train_loader, val_loader, test_loader


# ==============================================================
# 3Ô∏è‚É£ Model Definition
# ==============================================================

class EdgeClassifier(nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.lin = nn.Linear(hidden_channels * 2, out_channels)

    def forward(self, x, edge_index, edge_label_index):
        x = self.conv1(x, edge_index).relu()
        x = self.conv2(x, edge_index).relu()
        src, dst = edge_label_index
        edge_emb = torch.cat([x[src], x[dst]], dim=-1)
        return self.lin(edge_emb)


# ==============================================================
# 4Ô∏è‚É£ DDP Setup
# ==============================================================

def setup(rank, world_size):
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '12355'
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
    torch.cuda.set_device(rank)

def cleanup():
    dist.destroy_process_group()


# ==============================================================
# 5Ô∏è‚É£ Training Loop (Per GPU)
# ==============================================================

def train_worker(rank, world_size, data, splits):
    setup(rank, world_size)

    torch.manual_seed(42 + rank)

    (train_edges, train_labels), (val_edges, val_labels), (test_edges, test_labels) = splits
    train_loader, val_loader, _ = get_dataloaders(
        data, train_edges, val_edges, test_edges,
        train_labels, val_labels, test_labels,
        batch_size=4096
    )

    in_channels = data.x.size(-1)
    model = EdgeClassifier(in_channels, 128, 2).to(rank)
    model = DDP(model, device_ids=[rank])

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    loss_fn = nn.CrossEntropyLoss()

    for epoch in range(1, 21):
        model.train()
        total_loss = 0.0

        # ‚úÖ Show progress bar only on rank 0
        iterator = train_loader if rank != 0 else tqdm(train_loader, desc=f"Epoch {epoch} [Train]", ncols=120)
        for batch in iterator:
            batch = batch.to(rank)
            optimizer.zero_grad()
            pred = model(batch.x, batch.edge_index, batch.edge_label_index)
            loss = loss_fn(pred, batch.edge_label)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        # Validation only on rank 0
        if rank == 0:
            model.eval()
            val_loss, correct, total = 0.0, 0, 0
            with torch.no_grad():
                for batch in tqdm(val_loader, desc=f"Epoch {epoch} [Val]", ncols=120):
                    batch = batch.to(rank)
                    pred = model(batch.x, batch.edge_index, batch.edge_label_index)
                    val_loss += loss_fn(pred, batch.edge_label).item()
                    correct += (pred.argmax(dim=-1) == batch.edge_label).sum().item()
                    total += batch.edge_label.size(0)
            acc = correct / total
            print(f"[Epoch {epoch}] Train Loss: {total_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {acc:.4f}")

    cleanup()


# ==============================================================
# 6Ô∏è‚É£ Main Entry
# ==============================================================

if __name__ == "__main__":
    print("üöÄ Starting DDP training with progress bars...")

    # ‚ö†Ô∏è Replace with your real dataset here
    num_nodes = 1_000_000
    num_edges = 10_000_000
    data = Data(
        x=torch.randn(num_nodes, 41),  # your node features
        edge_index=torch.randint(0, num_nodes, (2, num_edges)),
        edge_label=torch.randint(0, 2, (num_edges,)),
    )

    splits = stratified_edge_split(data)

    world_size = torch.cuda.device_count()
    mp.spawn(train_worker, args=(world_size, data, splits), nprocs=world_size, join=True)
